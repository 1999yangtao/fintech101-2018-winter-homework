{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 货币政策最新消息聚合\n",
    "本课程的目的是制作一个国际货币政策的最新消息聚合。    \n",
    "通过汇集各国央行网站最新的货币政策消息，生成一个rss的信息源。\n",
    "\n",
    "## 预备知识\n",
    "1. python3.0以上基础 [https://www.python.org](https://www.python.org)\n",
    "2. python http访问库，[requests](http://www.python-requests.org/en/master/)\n",
    "3. python html解析库，[Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/)\n",
    "4. python web开发库， [flask](http://flask.pocoo.org/)\n",
    "5. [SQLite](https://www.sqlite.org/index.html)\n",
    "6. [SQLAlchemy](https://www.sqlalchemy.org/)\n",
    "6. [feedparser](https://pythonhosted.org/feedparser/index.html)\n",
    "\n",
    "## 数据来源\n",
    "1. [美联储](https://www.federalreserve.gov/feeds/press_all.xml) \n",
    "2. [欧洲央行](https://www.ecb.europa.eu/rss/press.xml)\n",
    "3. [日本央行](https://www.boj.or.jp/en/rss/whatsnew.xml)\n",
    "4. [英国央行]    \n",
    "   4.1 [事件](https://www.bankofengland.co.uk/rss/events)    \n",
    "   4.2 [新闻](https://www.bankofengland.co.uk/rss/news)\n",
    "5. [加拿大央行](https://www.bankofcanada.ca/content_type/press-releases/feed/)\n",
    "6. [新西兰央行](https://www.rbnz.govt.nz/feeds/news)\n",
    "7. 澳洲联储    \n",
    "   7.1 [公告](https://www.rba.gov.au/rss/rss-cb-bulletin.xml)    \n",
    "   7.2 [政策](https://www.rba.gov.au/rss/rss-cb-smp.xml)\n",
    "   \n",
    "## 数据存储\n",
    "### 数据库和数据表的创建\n",
    "我们在每个用户的项目目录下创建一个sqlite3的数据库文件及相应的数据表 \n",
    "\n",
    "        ~/rss$ sqlite3 rss.db    \n",
    "    SQLite version 3.23.1 2018-04-10 17:39:29     \n",
    "    Enter \".help\" for usage hints.    \n",
    "    sqlite>create table news(    \n",
    "        id integer primary key autoincrement,    \n",
    "        source varchar(32) not null,    \n",
    "        category varchar(128) not null,    \n",
    "        title varchar(256) not null,      \n",
    "        link varchar(256) unique not null,     \n",
    "        description text not null,     \n",
    "        pubDate datetime not null     \n",
    "    );  \n",
    "    \n",
    "- id 主键 自增长\n",
    "- source 消息来源 字符串\n",
    "- category 消息类别 字符串\n",
    "- title 标题 字符串\n",
    "- link 消息链接 字符串\n",
    "- description 更多内容 字符串\n",
    "- pubDate 发布消息的时间 时间类型\n",
    "\n",
    "**特别注意:link设置了唯一性索引，为了保证不重复保存相同的记录**\n",
    "\n",
    "### 使用SQLAlchemy往数据库中插入新闻记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import scoped_session, sessionmaker\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String, Text, DateTime\n",
    "from datetime import datetime\n",
    "\n",
    "engine = create_engine('sqlite://///home/jupyter-bcm/rss/rss.db', convert_unicode=True)\n",
    "db_session = scoped_session(sessionmaker(autocommit=False,\n",
    "                                         autoflush=False,\n",
    "                                         bind=engine))\n",
    "Base = declarative_base()\n",
    "Base.query = db_session.query_property()\n",
    "\n",
    "class News(Base):\n",
    "    __tablename__ = 'news'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    source = Column(String(32), nullable=False)\n",
    "    category = Column(String(128), nullable=False)\n",
    "    title = Column(String(256), nullable=False)\n",
    "    link = Column(String(256), unique=True, nullable=False)\n",
    "    description = Column(Text(), nullable=False)\n",
    "    pubDate = Column(DateTime(), nullable=False)\n",
    "    \n",
    "    def __init__(self, source=None, category=None, title=None, link=None, description=None, pubDate=None):\n",
    "        self.source = source;\n",
    "        self.category = category\n",
    "        self.title = title\n",
    "        self.link = link\n",
    "        self.description = description\n",
    "        self.pubDate = pubDate\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'title:{}|link:{}'.format(self.title, self.link)\n",
    "try:\n",
    "    n = News('us', 'cate1', 'titletest', 'https://www.federalreserve.gov', 'details', datetime.now())\n",
    "    db_session.add(n)\n",
    "    db_session.commit()\n",
    "except Exception as err:\n",
    "    #print(err)\n",
    "    db_session.rollback()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据的获取\n",
    "### 初始环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/11.1.2 Safari/605.1.15\n",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/11.1.2 Safari/605.1.15\n",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/11.1.2 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/11.1 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_2) AppleWebKit/604.4.7 (KHTML, like Gecko) Version/11.0.2 Safari/604.4.7',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/601.7.8 (KHTML, like Gecko) Version/9.1.3 Safari/601.7.8',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11) AppleWebKit/601.1.56 (KHTML, like Gecko) Version/9.0 Safari/601.1.56'\n",
    "]\n",
    "\n",
    "def get_user_agent():\n",
    "    i = random.randint(0, 9)\n",
    "    return user_agents[i]\n",
    "\n",
    "print(get_user_agent())\n",
    "print(get_user_agent())\n",
    "print(get_user_agent())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 时间格式转换\n",
    "因为消息来源的时间在不同的时区，统一转化为datetime类型(这里没有去做时区的转换，有兴趣的同学可自行完成)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-17 14:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_timestamp(dtstring, dtformat):\n",
    "    return datetime.strptime(dtstring, dtformat)\n",
    "\n",
    "print(get_timestamp('Wed, 17 Oct 2018 14:00:00 GMT', '%a, %d %b %Y %H:%M:%S GMT'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 美联储数据的获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "feedparser.USER_AGENT = get_user_agent()\n",
    "d = feedparser.parse('https://www.federalreserve.gov/feeds/press_all.xml')\n",
    "for item in d.entries:\n",
    "    try:\n",
    "        n = News('federalreserve.gov', item.category, item.title, item.link, item.description, get_timestamp(item.published, '%a, %d %b %Y %H:%M:%S GMT'))\n",
    "        db_session.add(n)\n",
    "        db_session.commit()\n",
    "    except Exception as err:\n",
    "        #print(err)\n",
    "        db_session.rollback()\n",
    "        continue\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 欧洲央行数据的获取\n",
    "由于该数据源返回无category和description字段，所以做了简单的处理。    \n",
    "category写为: other    \n",
    "description用title代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "feedparser.USER_AGENT = get_user_agent()\n",
    "d = feedparser.parse('https://www.ecb.europa.eu/rss/press.xml')\n",
    "for item in d.entries:\n",
    "    try:\n",
    "        n = News('ecb.europa.eu', 'other', item.title, item.link, item.title, get_timestamp(item.published, '%a, %d %b %Y'))\n",
    "        db_session.add(n)\n",
    "        db_session.commit()\n",
    "    except Exception as err:\n",
    "        #print(err)\n",
    "        db_session.rollback()\n",
    "        continue\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 日本央行数据的获取\n",
    "由于该数据源返回无category和description字段，所以做了简单的处理。    \n",
    "category写为: other    \n",
    "description用title代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "feedparser.USER_AGENT = get_user_agent()\n",
    "d = feedparser.parse('https://www.boj.or.jp/en/rss/whatsnew.xml')\n",
    "for item in d.entries:\n",
    "    try:\n",
    "        n = News('boj.or.jp', 'other', item.title, item.link, item.title, get_timestamp(item.published, '%a, %d %b %Y %H:%M:%S +0900'))\n",
    "        db_session.add(n)\n",
    "        db_session.commit()\n",
    "    except Exception as err:\n",
    "        #print(err)\n",
    "        db_session.rollback()\n",
    "        continue\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 英国央行数据的获取\n",
    "由于该数据源返回无category字段，所以做了简单的处理。    \n",
    "category写为: other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "feedparser.USER_AGENT = get_user_agent()\n",
    "\n",
    "d = feedparser.parse('https://www.bankofengland.co.uk/rss/events')\n",
    "for item in d.entries:\n",
    "    try:\n",
    "        if ' Z' in item.published: \n",
    "            n = News('bankofengland.co.uk', 'other', item.title, item.link, item.description, get_timestamp(item.published, '%a, %d %b %Y %H:%M:%S Z'))\n",
    "        else:\n",
    "            n = News('bankofengland.co.uk', 'other', item.title, item.link, item.description, get_timestamp(item.published, '%a, %d %b %Y %H:%M:%S +0100'))        \n",
    "        db_session.add(n)\n",
    "        db_session.commit()\n",
    "    except Exception as err:\n",
    "        #print(err)\n",
    "        db_session.rollback()\n",
    "        continue\n",
    "    \n",
    "d = feedparser.parse('https://www.bankofengland.co.uk/rss/news')\n",
    "for item in d.entries:\n",
    "    try:\n",
    "        if ' Z' in item.published: \n",
    "            n = News('bankofengland.co.uk', 'other', item.title, item.link, item.description, get_timestamp(item.published, '%a, %d %b %Y %H:%M:%S Z'))\n",
    "        else:\n",
    "            n = News('bankofengland.co.uk', 'other', item.title, item.link, item.description, get_timestamp(item.published, '%a, %d %b %Y %H:%M:%S +0100'))\n",
    "        db_session.add(n)\n",
    "        db_session.commit()\n",
    "    except Exception as err:\n",
    "        #print(err)\n",
    "        db_session.rollback()\n",
    "        continue\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加拿大央行数据的获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "feedparser.USER_AGENT = get_user_agent()\n",
    "d = feedparser.parse('https://www.bankofcanada.ca/content_type/press-releases/feed/')\n",
    "for item in d.entries:\n",
    "    try: \n",
    "        n = News('bankofcanada.ca', 'other', item.title, item.link, item.description, get_timestamp(item.updated, '%Y-%m-%dT%H:%M:%S+00:00'))\n",
    "        db_session.add(n)\n",
    "        db_session.commit()\n",
    "    except Exception as err:\n",
    "        #print(err)\n",
    "        db_session.rollback()\n",
    "        continue\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新西兰央行数据的获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "feedparser.USER_AGENT = get_user_agent()\n",
    "d = feedparser.parse('https://www.rbnz.govt.nz/feeds/news')\n",
    "for item in d.entries:\n",
    "    try: \n",
    "        if '+1200' in item.published:\n",
    "            n = News('rbnz.govt.nz', 'other', item.title, item.link, item.description, get_timestamp(item.published, '%a, %d %b %Y %H:%M:%S +1200'))\n",
    "        else:\n",
    "            n = News('rbnz.govt.nz', 'other', item.title, item.link, item.description, get_timestamp(item.published, '%a, %d %b %Y %H:%M:%S +1300'))\n",
    "        db_session.add(n)\n",
    "        db_session.commit()\n",
    "    except Exception as err:\n",
    "        #print(err)\n",
    "        db_session.rollback()\n",
    "        continue\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 澳洲联储数据的获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "feedparser.USER_AGENT = get_user_agent()\n",
    "\n",
    "d = feedparser.parse('https://www.rba.gov.au/rss/rss-cb-bulletin.xml')\n",
    "for item in d.entries:\n",
    "    try: \n",
    "        n = News('rba.gov.au', 'other', item.title, item.link, item.description, get_timestamp(item.updated, '%Y-%m-%dT%H:%M:%S+10:00'))\n",
    "        db_session.add(n)\n",
    "        db_session.commit()\n",
    "    except Exception as err:\n",
    "        #print(err)\n",
    "        db_session.rollback()\n",
    "        continue\n",
    "    \n",
    "d = feedparser.parse('https://www.rba.gov.au/rss/rss-cb-smp.xml')\n",
    "for item in d.entries:\n",
    "    try: \n",
    "        n = News('rba.gov.au', 'other', item.title, item.link, item.description, get_timestamp(item.updated, '%Y-%m-%dT%H:%M:%S+10:00'))\n",
    "        db_session.add(n)\n",
    "        db_session.commit()\n",
    "    except Exception as err:\n",
    "        #print(err)\n",
    "        db_session.rollback()\n",
    "        continue\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成一个新的聚合rss源\n",
    "我们使用flask从数据库中读取数据，并生成rss源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:9000/ (Press CTRL+C to quit)\n",
      "45.124.24.36 - - [22/Oct/2018 06:52:14] \"\u001b[37mGET /rss HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from flask import Flask\n",
    "from flask import request\n",
    "from sqlalchemy import desc\n",
    "import PyRSS2Gen\n",
    "import datetime\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/rss\")\n",
    "def rss():\n",
    "    items = News.query.order_by(desc(News.pubDate)).limit(100)\n",
    "    rss_items = []\n",
    "    for item in items:\n",
    "        ri = PyRSS2Gen.RSSItem(\n",
    "            title = item.title,\n",
    "            link = item.link,\n",
    "            description = item.description,\n",
    "            guid = PyRSS2Gen.Guid(item.link),\n",
    "            pubDate = item.pubDate\n",
    "        )\n",
    "        rss_items.append(ri)\n",
    "    \n",
    "    rss = PyRSS2Gen.RSS2(\n",
    "        title = 'Recent Monetary News', \n",
    "        link = request.url,\n",
    "        description = 'Recent Monetary News',\n",
    "        lastBuildDate = datetime.datetime.now(),\n",
    "        items = rss_items)\n",
    "    \n",
    "    return rss.to_xml(), 200, {'Content-Type': 'application/xml'}\n",
    "\n",
    "# 由于每个用户的应用实例都在同一台服务器上，建议同学们把自己学号的后两位数用在9000后两位数字上，比如9022\n",
    "# 这样子，你如果运行正常，那么访问这个rss源的地址为：http://lab.ftcourse.cn:9022/rss\n",
    "app.run(host='0.0.0.0', port=9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 待改进的地方和建议\n",
    "这个应用有几个地方并不完善，有兴趣的同学可以从下面几点去尝试改进它：\n",
    "\n",
    "1. 时区转换，大家可以看到我并没有可以去处理不同国家来源数据的日期的时区问题。可以把所有时区都转换为北京的时区然后再存储。\n",
    "2. 空缺字段的处理，有些数据源返回的数据并没有rss规范所要求的category和description，在现在的代码中我仅仅是做了简化处理，可尝试从link中去获取详情页里面的内容，然后分词，然后获取有用信息用来填充缺失字段。\n",
    "3. 在对2的处理中，如果有兴趣的同学可以接触下nlp，就是自然语言处理的部分内容，python在这块也很有优势。\n",
    "4. 由于在jupyter环境下缺乏定时处理和与系统交互的方法，如果能写成独立的代码，可对这些不同数据源进行定时获取，获取更新的数据。\n",
    "5. 对于4的处理，目前jupyter notebook文件可通过nbconvert命令行工具来执行，有兴趣同学可参考jupyter官方文档。\n",
    "\n",
    "下面推荐两个网站：\n",
    "- [nlp](https://www.nltk.org)\n",
    "- [jupyter command tool](https://nbconvert.readthedocs.io/en/latest/usage.html#)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
